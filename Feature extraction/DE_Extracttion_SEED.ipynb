{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Way 1 : From The ExtractedFeatures Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import scipy.io as sio\n",
    "from sklearn.utils import shuffle \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing the mat files\n",
    "mat_folder = \"E:/STUDY/Publications/Thesis/Brain Emotion Detection/Dataset/Practice with datasets/Seed/ExtractedFeatures\"\n",
    "\n",
    "# Initialize arrays to store data sizes and maximum size\n",
    "sizes = []\n",
    "max_vals = 0\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(mat_folder):\n",
    "    if filename.endswith(\".mat\"):\n",
    "        mat_file = os.path.join(mat_folder, filename)\n",
    "        loaded_data = loadmat(mat_file)\n",
    "        # Loop through the variables in the loaded file\n",
    "        for var_name in loaded_data:\n",
    "            # Check if the variable name starts with 'de_LDS'\n",
    "            if var_name.startswith('de_LDS') and isinstance(loaded_data[var_name], np.ndarray) and len(loaded_data[var_name].shape) == 3:\n",
    "                sizes.append(loaded_data[var_name].shape[1])\n",
    "                max_vals = max(max_vals, loaded_data[var_name].shape[1])\n",
    "\n",
    "print(max_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data array: (30, 62, 265, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate the total number of trials\n",
    "total_trials = 30\n",
    "\n",
    "# Initialize the data array\n",
    "data = np.zeros((total_trials, 62, max_vals, 5))\n",
    "\n",
    "# Loop through all files and variables again to load data\n",
    "index = 0\n",
    "for filename in os.listdir(mat_folder):\n",
    "    if filename.endswith(\".mat\"):\n",
    "        mat_file = os.path.join(mat_folder, filename)\n",
    "        loaded_data = loadmat(mat_file)\n",
    "        \n",
    "        for var_name in loaded_data:\n",
    "            # Check if the variable name starts with 'de_LDS'\n",
    "            if var_name.startswith('de_LDS') and isinstance(loaded_data[var_name], np.ndarray) and len(loaded_data[var_name].shape) == 3:\n",
    "                num_channels = loaded_data[var_name].shape[0]\n",
    "                num_elements = loaded_data[var_name].shape[1]\n",
    "                data[index, :num_channels, :num_elements, :] = loaded_data[var_name]\n",
    "                index += 1\n",
    "\n",
    "# Print the shape of the data array\n",
    "print(\"Shape of data array:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Way 2: From the Preprocessed eeg\n",
    "\n",
    "https://www.programmersought.com/article/336211155520/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5, 62, 265)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def compute_DE(signal):\n",
    "    variance = np.var(signal, ddof=1)\n",
    "    return math.log(2 * math.pi * math.e * variance) / 2\n",
    "\n",
    "def load_data():\n",
    "    data_dir = \"E:/STUDY/Publications/Thesis/Brain Emotion Detection/Dataset/Practice with datasets/Seed/Preprocessed_EEG/\"\n",
    "    fs = 200\n",
    "    fStart = [1, 4, 8, 14, 31]\n",
    "    fEnd = [3, 7, 13, 30, 50]\n",
    "    all_channels = range(62)\n",
    "\n",
    "    filename_label = \"label\"\n",
    "    label = loadmat(data_dir + filename_label)\n",
    "    label = label[\"label\"][0]\n",
    "\n",
    "    datasets_X, datasets_y = [], []\n",
    "\n",
    "    for filename_data in os.listdir(data_dir):\n",
    "        if filename_data in [\"label.mat\", \"readme.txt\"]:\n",
    "            continue\n",
    "\n",
    "        data_all = loadmat(data_dir + filename_data)\n",
    "        scenes = list(data_all.keys())[3:]\n",
    "\n",
    "        for index, scene in enumerate(scenes):\n",
    "            dataset_X = []\n",
    "            data = data_all[scene][:,]  # Considering all channels\n",
    "\n",
    "            for band_index, band in enumerate(fStart):\n",
    "                b, a = signal.butter(4, [fStart[band_index]/fs, fEnd[band_index]/fs], 'bandpass')\n",
    "                filtedData = signal.filtfilt(b, a, data)\n",
    "                filtedData_de = []\n",
    "\n",
    "                for lead in all_channels:\n",
    "                    filtedData_split = []\n",
    "                    for de_index in range(0, filtedData.shape[1] - fs, fs):\n",
    "                        filtedData_split.append(compute_DE(filtedData[lead, de_index: de_index + fs]))\n",
    "                    if len(filtedData_split) < 265:  # Max point size is 53001 so, 53001/200 = 265\n",
    "                        filtedData_split += [0] * (265-len(filtedData_split))\n",
    "                    filtedData_de.append(filtedData_split)\n",
    "                \n",
    "                filtedData_de = np.array(filtedData_de)\n",
    "                dataset_X.append(filtedData_de)\n",
    "\n",
    "            datasets_X.append(dataset_X)\n",
    "            datasets_y.append(label[index])\n",
    "\n",
    "    datasets_X, datasets_y = np.array(datasets_X), np.array(datasets_y)\n",
    "\n",
    "    return datasets_X, datasets_y\n",
    "\n",
    "\n",
    "datasets_X, datasets_y = load_data()\n",
    "print(datasets_X.shape)\n",
    "print(datasets_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 62, 265, 5)\n"
     ]
    }
   ],
   "source": [
    "new_datasets_X = np.copy(datasets_X)\n",
    "new_datasets_X = np.transpose(new_datasets_X, (0, 2, 3, 1))\n",
    "print(new_datasets_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('SEED_DE_X.npy', new_datasets_X)\n",
    "np.save('SEED_DE_y.npy', datasets_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = np.load(\"E:/STUDY/Publications/Thesis/Brain Emotion Detection/Dataset/Practice with datasets/Seed/DE_SEED_X_y/SEED_DE_X.npy\")\n",
    "y  = np.load(\"E:/STUDY/Publications/Thesis/Brain Emotion Detection/Dataset/Practice with datasets/Seed/DE_SEED_X_y/SEED_DE_y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "file_path = 'E:/STUDY/Publications/Thesis/Brain Emotion Detection/Dataset/Practice with datasets/Seed/Preprocessed_EEG/1_20131027.mat'\n",
    "fs = 200\n",
    "fStart = [1, 4, 8, 14, 31]\n",
    "fEnd = [3, 7, 13, 30, 50]\n",
    "channel = [3, 7, 13, 23]\n",
    "\n",
    "# Assuming data is defined before the loop\n",
    "# data = ...\n",
    "data_all = loadmat(file_path)\n",
    "data = data_all['djc_eeg2'][channel]\n",
    "\n",
    "for band_index, band in enumerate(fStart):\n",
    "    b, a = signal.butter(4, [fStart[band_index]/fs, fEnd[band_index]/fs], 'bandpass')\n",
    "    filtedData = signal.filtfilt(b, a, data)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for lead in range(filtedData.shape[0]):\n",
    "        plt.subplot(filtedData.shape[0], 1, lead+1)\n",
    "        plt.plot(filtedData[lead, :], label=f'Channel {lead+1}')\n",
    "        plt.title(f'Filtered Data - Band {band_index} - Channel {lead+1}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_code_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
